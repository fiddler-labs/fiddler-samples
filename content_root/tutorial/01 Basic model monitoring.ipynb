{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring with No Model [Basic]\n",
    "For this section, we will cover how to begin monitoring with only a prediction\n",
    "log. We will do so by sending monitoring events for a specific model and \n",
    "project we configure.\n",
    "\n",
    "Specifically, we will:\n",
    "- Initialize a connection with Fiddler\n",
    "- Load a prediction log\n",
    "- Create a project\n",
    "- Create a model using the prediction log\n",
    "- Send monitoring events "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n",
    "We begin this section as usual by establishing a connection to our\n",
    "Fiddler instance. We can establish this connection either by specifying \n",
    "our credentials directly, or by utilizing our `fiddler.ini` file. More\n",
    "information can be found in the [setup](https://github.com/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/00%20Setup.ipynb) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "\n",
    "# client = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=auth_token)\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Prediction Log\n",
    "\n",
    "Prediction logs must contains the model's input features and predictions. This is information\n",
    "that can be collected while a model is running in production. For this demonstration, we have\n",
    "collected events and saved them in a file called `p2p_production.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction_log_df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_production.log')\n",
    "prediction_log_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Project\n",
    "Projects are one of the key entities of Fiddler. They are convenient containers \n",
    "for housing the models and datasets associated with a given ML use case. Specifics about\n",
    "projects can be found [here](https://docs.fiddler.ai/components/#project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'tutorial'\n",
    "model_id = 'no_model_artifact'\n",
    "\n",
    "if project_id in client.list_projects():\n",
    "    client.delete_model(project_id, model_id)\n",
    "    client.delete_dataset(model_id)\n",
    "else:\n",
    "    client.create_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Using Prediction Log\n",
    "With our project now created, we will now create a model using the prediction log.\n",
    "Models are another one of the key entities of Fiddler, and we will create \n",
    "this model will be used for generating relevant schema information. More \n",
    "information about models can be found [here](https://docs.fiddler.ai/components/#model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputs = ['probability_fully_paid']\n",
    "\n",
    "is_feature = lambda x: x not in outputs\n",
    "features = list(filter(is_feature, list(prediction_log_df.columns)))\n",
    "\n",
    "client.create_model_from_prediction_log(\n",
    "    project_id,\n",
    "    model_id,\n",
    "    prediction_log_df,\n",
    "    features,\n",
    "    outputs,\n",
    "    model_task=fdl.ModelTask.BINARY_CLASSIFICATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and cache model predictions\n",
    "Before sending events, we need to compute model predictions and cache them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.trigger_model_predictions(project_id, model_id, dataset_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Monitoring Events\n",
    "\n",
    "### First Option\n",
    "In this step, we will be simulating traffic to send for our model monitoring by using \n",
    "[publish_event](https://docs.fiddler.ai/api-reference/python-package/#publish-event). \n",
    "This will be the equivalent of running our model separately on data, and either \n",
    "sending to Fiddler then, or saving this information to a log and sending at a later point.\n",
    "\n",
    "For this demonstration, we will be going with a log-related approach. \n",
    "This log contains rows that have inputs and predictions. \n",
    "To most accurately simulate this as a time-series event, we will generate a timestamp and send an event every 5 minutes. Real data will ideally have a timestamp related to when the event took place; otherwise, the current \n",
    "time will be used.\n",
    "\n",
    "We can send the inputs, outputs, targets as well as decisions variables.\n",
    "\n",
    "**Note**: The timestamp must be in UTC milliseconds. See \n",
    "[here](https://docs.fiddler.ai/api-reference/python-package/#publish-event) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "NUM_EVENTS_TO_SEND = 50\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "start_date = now - datetime.timedelta(days=2)\n",
    "print(start_date.isoformat(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this dataframe into a list of dictionary events, where each event is its own dictionary\n",
    "event_list_dict = prediction_log_df.sample(n=NUM_EVENTS_TO_SEND, random_state=42).to_dict(orient='records') \n",
    "\n",
    "for ind, event_dict in enumerate(event_list_dict):\n",
    "    event_time = start_date + datetime.timedelta(minutes=5)* ind\n",
    "    result = client.publish_event(project_id,\n",
    "                                  model_id,\n",
    "                                  event_dict,\n",
    "                                  event_time_stamp=event_time,\n",
    "                                  event_id=str(ind + 100),\n",
    "                                  update_event=False)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    print(f'Sending {ind+1} / {NUM_EVENTS_TO_SEND} \\n{event_time} UTC: \\n{event_dict}')\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If we want to update the events later, we need to specify an `event_id`. To update an event, we need to call `publish_event` again with the same `event_id` and `update_event=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second option\n",
    "As an alternative, we can send a log dataframe in once by using [publish_events_log](https://docs.fiddler.ai/api-reference/python-package/#publish-events-log).\n",
    "\n",
    "We can embed the `event_timestamp` as a field in the input data frame and then use the `ts_column` to specify which column to use for timestamp. If the timestamp is not provided, the current time will be used.\n",
    "\n",
    "We can send the inputs, outputs, targets as well as decisions variables.\n",
    "\n",
    "**Note**: The timestamp must be in UTC milliseconds. See \n",
    "[here](https://docs.fiddler.ai/api-reference/python-package/#publish-event) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_timestamp = [start_date + datetime.timedelta(minutes=5) * ind for ind in range(NUM_EVENTS_TO_SEND)]\n",
    "list_timestamp = [x.isoformat(' ') for x in list_timestamp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can also embed the `event_id` as a field in the input data if we want to update those events later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = [str(x) for x in range(NUM_EVENTS_TO_SEND)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_log = pd.concat([prediction_log_df.sample(n=NUM_EVENTS_TO_SEND, random_state=42),\n",
    "                       pd.Series(time, name='timestamp'),\n",
    "                       pd.Series(event_id, name='__event_id')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.publish_events_log(project_id,\n",
    "                          model_id,\n",
    "                          event_log,\n",
    "                          ts_column='timestamp'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
