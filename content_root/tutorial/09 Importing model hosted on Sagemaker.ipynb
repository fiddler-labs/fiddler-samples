{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Predict API On Model Hosted on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Fiddler Client\n",
    "We begin this section as usual by establishing a connection to our\n",
    "Fiddler instance. We can establish this connection either by specifying \n",
    "our credentials directly, or by utilizing our `fiddler.ini` file. More\n",
    "information can be found in the [setup](https://github.com/fiddler-labs/fiddler-samples/blob/master/content_root/tutorial/00%20Setup.ipynb) section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiddler as fdl\n",
    "\n",
    "# client = fdl.FiddlerApi(url=url, org_id=org_id, auth_token=auth_token)\n",
    "client = fdl.FiddlerApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset\n",
    "To upload a model, you first need to upload a sample of the data of the model’s \n",
    "inputs, targets, and additional metadata that might be useful for model analysis. \n",
    "This data sample helps us (among other things) to infer the model schema and the \n",
    "data types and values range of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'fico_range_low', 'total_acc']\n",
    "target = 'loan_status'\n",
    "dataset_id = 'p2p_loans'\n",
    "\n",
    "if dataset_id in client.list_datasets():\n",
    "    df = client.get_dataset(dataset_id)['test']\n",
    "    df_schema = client.get_dataset_info(dataset_id)\n",
    "else:\n",
    "    df = pd.read_csv('/app/fiddler_samples/samples/datasets/p2p_loans/p2p_loans.csv')\n",
    "    df_schema = fdl.DatasetInfo.from_dataframe(df, max_inferred_cardinality=1000)\n",
    "    upload_result = client.upload_dataset(\n",
    "        dataset={'test': df}, \n",
    "        dataset_id=dataset_id,\n",
    "        info=df_schema)\n",
    "    \n",
    "df_input = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Write Model Info\n",
    "As you must have noted, in the dataset upload step we did not ask for the model’s \n",
    "features and targets, or any model specific information. That’s because we \n",
    "allow for linking multiple models to a given dataset schema. Hence we require \n",
    "an Infer model schema step which helps us know the features relevant to the \n",
    "model and the model task. Here you can specify the input features, the target \n",
    "column, decision columns and metadata columns, and also the type of model.\n",
    "\n",
    "We will save this information in a `model.yaml` file within our model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "project_id = 'tutorial'\n",
    "model_id = 'sagemaker_hosted_model'\n",
    "\n",
    "model_info = fdl.ModelInfo.from_dataset_info(\n",
    "    dataset_info=client.get_dataset_info(dataset_id),\n",
    "    target=target, \n",
    "    features=features,\n",
    "    display_name='SagemakerHostedModel',\n",
    "    description='this model is hosted on Sagemaker.'\n",
    ")\n",
    "\n",
    "# create temp dir\n",
    "model_dir = pathlib.Path(model_id)\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "model_dir.mkdir()\n",
    "\n",
    "# save model schema\n",
    "with open(model_dir / 'model.yaml', 'w') as yaml_file:\n",
    "    yaml.dump({'model': model_info.to_dict()}, yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write `package.py`\n",
    "A wrapper is needed between Fiddler and the model. This wrapper can be used to \n",
    "translate the inputs and outputs to fit what the model expects and what Fiddler \n",
    "is able to consume. More information can be found [here](https://docs.fiddler.ai/api-reference/package-py/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sagemaker_hosted_model/package.py\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import random\n",
    "from io import StringIO\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "PACKAGE_PATH = Path(__file__).parent\n",
    "\n",
    "class SklearnModelPackage:\n",
    "    is_classifier = False\n",
    "    output_columns = ['probability_Fully Paid']\n",
    "    endpoint_name = 'sagemaker-xgboost-lending'\n",
    "    content_type = \"text/csv\"                                        \n",
    "    accept = \"application/json\"\n",
    "    region = 'us-west-2'\n",
    "    aws_access_key_id ='...'\n",
    "    aws_secret_access_key='...'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = boto3.client('sagemaker-runtime', region_name=self.region, \n",
    "                      aws_access_key_id=self.aws_access_key_id, \n",
    "                      aws_secret_access_key=self.aws_secret_access_key)\n",
    "        \n",
    "    def predict(self, input_df):\n",
    "        payload = input_df.to_csv(index=False, header=False)\n",
    "        return self.call_sagemaker(payload)\n",
    "\n",
    "    def call_sagemaker(self, payload):\n",
    "        custom_attributes = f'fiddler-sagemaker-id-{random.randint(0, 10000000)}'\n",
    "        response = self.client.invoke_endpoint(\n",
    "            EndpointName=self.endpoint_name, \n",
    "            CustomAttributes=custom_attributes, \n",
    "            ContentType=self.content_type,\n",
    "            Accept=self.accept,\n",
    "            Body=payload\n",
    "        )\n",
    "        csv_str = ''\n",
    "        for row in response['Body']:\n",
    "            csv_str += row.decode('utf-8')\n",
    "            \n",
    "        pd_array = pd.array(csv_str.split(','))\n",
    "        pd_array = pd.to_numeric(pd_array, errors='coerce')\n",
    "        return pd.DataFrame(pd_array, columns=self.output_columns)\n",
    "    \n",
    "def get_model():\n",
    "    return SklearnModelPackage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Model Package\n",
    "Now that we have all the parts that we need, we can go ahead and upload the model to the Fiddler platform. You can use the [upload_model_package](https://docs.fiddler.ai/api-reference/python-package/#upload-model-package) to upload this entire directory in one shot. We need the following for uploading a model:\n",
    "- The `path` to the model directory\n",
    "- The `project_id` to which the model belongs\n",
    "- The `model_id`, which is the name you want to give the model. You can access it in Fiddler henceforth via this ID\n",
    "- The `dataset` which the model is linked to (optional)  \n",
    "\n",
    "For this Sagemaker example, we will have a `model.yaml`, and a `package.py` file within our model directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_model(project_id, model_id)\n",
    "client.upload_model_package(model_dir, project_id, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "Now, let's test out our model by interfacing with the client and \n",
    "calling [run model](https://docs.fiddler.ai/api-reference/python-package/#run-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = df_input[0: 10]\n",
    "result = client.run_model(project_id, model_id, prediction_input)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
